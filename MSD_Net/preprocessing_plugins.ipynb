{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "freelance-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-glass",
   "metadata": {},
   "source": [
    "Categories:\n",
    "- 0: background\n",
    "- 1: crystal\n",
    "- 2: loop\n",
    "- 3: liquor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prime-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_folder(path, dataset_name, type_name):\n",
    "    assert str(type_name) in [\"recon\", \"gt\"]\n",
    "    filenames = glob.glob(path + \"*.tif\")\n",
    "    print(\"DATASET:\", dataset_name, \"TYPE:\", type_name, \"N_FILES:\", len(filenames))\n",
    "    for n, f in enumerate(filenames):\n",
    "        new_name = str(dataset_name) + \"_\" + str(type_name) + \"_\" + str(n).zfill(5) + \".tif\"\n",
    "        os.rename(f, path + new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "descending-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/dls/science/users/lqg38422/DATA/13769/recon/\"\n",
    "filenames = glob.glob(path + \"*.tif\")\n",
    "dataset_name = \"13769\"\n",
    "type_name = \"recon\"\n",
    "for n, f in enumerate(filenames):\n",
    "    new_name = str(dataset_name) + \"_\" + str(type_name) + \"_\" + str(n).zfill(5) + \".tif\"\n",
    "    os.rename(f, path + new_name)\n",
    "    \n",
    "path = \"/dls/science/users/lqg38422/DATA/13769/gt/\"\n",
    "filenames = glob.glob(path + \"*.tif\")\n",
    "dataset_name = \"13769\"   \n",
    "type_name = \"gt\"  \n",
    "for n, f in enumerate(filenames):\n",
    "    new_name = str(dataset_name) + \"_\" + str(type_name) + \"_\" + str(n).zfill(5) + \".tif\"\n",
    "    os.rename(f, path + new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "later-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensors(tensor, shape):\n",
    "    h, w = tensor.shape\n",
    "    nh, nw = shape\n",
    "    up_down = (int(np.floor((nh - h)/2)), int(np.ceil((nh - h)/2)))\n",
    "    left_right = (int(np.floor((nw - w)/2)), int(np.ceil((nw - w)/2)))\n",
    "    tensor = np.pad(tensor, (up_down, left_right), 'constant')\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "realistic-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_im(im):\n",
    "    return (im - im.min())/(im.max() - im.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vocational-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_folder(path, shape, normalise=True):\n",
    "    filenames = glob.glob(path)\n",
    "    for f in filenames:\n",
    "        im = Image.open(f)\n",
    "        im = np.array(im)\n",
    "        if normalise:\n",
    "            im = normalise_im(im)\n",
    "        im = pad_tensors(im, shape)\n",
    "        im = Image.fromarray(im)\n",
    "        im.save(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mental-hartford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘/dls/tmp/lqg38422/VALIDATION/recon/*’: No such file or directory\n",
      "rm: cannot remove ‘/dls/tmp/lqg38422/VALIDATION/gt/*’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Before starting empty train folder\n",
    "!rm /dls/tmp/lqg38422/TRAIN/recon/*\n",
    "!rm /dls/tmp/lqg38422/TRAIN/gt/*\n",
    "\n",
    "!rm /dls/tmp/lqg38422/VALIDATION/recon/*\n",
    "!rm /dls/tmp/lqg38422/VALIDATION/gt/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "binary-links",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DATASET 13068 ---\n",
      "Copying recon...\n",
      "Copying gt...\n",
      "Done!\n",
      "--- DATASET 13076 ---\n",
      "Copying recon...\n",
      "Copying gt...\n",
      "Done!\n",
      "--- DATASET 13246 ---\n",
      "Copying recon...\n",
      "Copying gt...\n",
      "Done!\n",
      "--- DATASET 13270 ---\n",
      "Copying recon...\n",
      "Copying gt...\n",
      "Done!\n",
      "--- DATASET 13295 ---\n",
      "Copying recon...\n",
      "Copying gt...\n",
      "Done!\n",
      "--- DATASET 13551 ---\n",
      "Copying recon...\n",
      "Copying gt...\n",
      "Done!\n",
      "--- DATASET 13724 ---\n",
      "Copying recon...\n",
      "Copying gt...\n",
      "Done!\n",
      "--- DATASET 14253 ---\n",
      "Copying recon...\n",
      "Copying gt...\n",
      "Done!\n",
      "Padding recon...\n",
      "Padding gt...\n",
      "Training data time: 466.56566071510315\n",
      "--- DATASET 13737 ---\n",
      "Copying recon...\n",
      "Copying gt...\n",
      "Done!\n",
      "Padding recon...\n",
      "Padding gt...\n",
      "Validation data time: 89.50831747055054\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Paths\n",
    "train_path_reco = \"/dls/tmp/lqg38422/TRAIN/recon/*\"\n",
    "train_path_gt = \"/dls/tmp/lqg38422/TRAIN/gt/*\"\n",
    "\n",
    "val_path_reco = \"/dls/tmp/lqg38422/VALIDATION/recon/*\"\n",
    "val_path_gt = \"/dls/tmp/lqg38422/VALIDATION/gt/*\"\n",
    "\n",
    "# Select training/validation datasets\n",
    "train_datasets = [\"13068\", \"13076\", \"13246\", \"13270\", \"13295\", \"13551\", \"13724\", \"13737\", \"13769\", \"14253\"] #14116 FBP\n",
    "#val_datasets = [\"13737\"]\n",
    "test_datasets = [\"13284\"]\n",
    "\n",
    "# Parameters\n",
    "shape = (900, 900)\n",
    "\n",
    "# Add training data\n",
    "t = time.time()\n",
    "for dataset in train_datasets:\n",
    "    print(f\"--- DATASET {dataset} ---\")\n",
    "    \n",
    "    recon_path = f\"/dls/science/users/lqg38422/DATA/{dataset}/recon/\"\n",
    "    gt_path = f\"/dls/science/users/lqg38422/DATA/{dataset}/gt/\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # 1. Rename\n",
    "    print(\"Renaming...\")\n",
    "    recon_path = f\"/dls/science/users/lqg38422/DATA/{dataset}/recon/\"\n",
    "    rename_folder(recon_path, dataset, \"recon\")\n",
    "    gt_path = f\"/dls/science/users/lqg38422/DATA/{dataset}/gt/\"\n",
    "    rename_folder(gt_path, dataset, \"gt\")\n",
    "    print(\"Done!\")\n",
    "    \"\"\"\n",
    "    \n",
    "    # 2. Copy files\n",
    "    print(\"Copying recon...\")\n",
    "    for filename in glob.glob(recon_path + \"*\"):\n",
    "        shutil.copy(filename, train_path_reco[:-1])\n",
    "    print(\"Copying gt...\")\n",
    "    for filename in glob.glob(gt_path + \"*\"):\n",
    "        shutil.copy(filename, train_path_gt[:-1])\n",
    "    print(\"Done!\")\n",
    "    \n",
    "# 3. Pad all files\n",
    "print(\"Padding recon...\")\n",
    "pad_folder(train_path_reco, shape, normalise=True)\n",
    "print(\"Padding gt...\")\n",
    "pad_folder(train_path_gt, shape, normalise=False)\n",
    "\n",
    "res = time.time() - t\n",
    "print(\"Training data time:\", res)\n",
    "\n",
    "\n",
    "# Add validation data\n",
    "t = time.time()\n",
    "for dataset in val_datasets:\n",
    "    print(f\"--- DATASET {dataset} ---\")\n",
    "    \n",
    "    recon_path = f\"/dls/science/users/lqg38422/DATA/{dataset}/recon/\"\n",
    "    gt_path = f\"/dls/science/users/lqg38422/DATA/{dataset}/gt/\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # 1. Rename\n",
    "    print(\"Renaming...\")\n",
    "    recon_path = f\"/dls/science/users/lqg38422/DATA/{dataset}/recon/\"\n",
    "    rename_folder(recon_path, dataset, \"recon\")\n",
    "    gt_path = f\"/dls/science/users/lqg38422/DATA/{dataset}/gt/\"\n",
    "    rename_folder(gt_path, dataset, \"gt\")\n",
    "    print(\"Done!\")\n",
    "    \"\"\"\n",
    "    \n",
    "    # 2. Copy files\n",
    "    print(\"Copying recon...\")\n",
    "    for filename in glob.glob(recon_path + \"*\"):\n",
    "        shutil.copy(filename, val_path_reco[:-1])\n",
    "    print(\"Copying gt...\")\n",
    "    for filename in glob.glob(gt_path + \"*\"):\n",
    "        shutil.copy(filename, val_path_gt[:-1])\n",
    "    print(\"Done!\")\n",
    "    \n",
    "# 3. Pad all files\n",
    "print(\"Padding recon...\")\n",
    "pad_folder(val_path_reco, shape, normalise=True)\n",
    "print(\"Padding gt...\")\n",
    "pad_folder(val_path_gt, shape, normalise=False)\n",
    "\n",
    "res = time.time() - t\n",
    "print(\"Validation data time:\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "authentic-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set recon to float16\n",
    "\n",
    "def normalise(im):\n",
    "    return (im - im.min())/(im.max() - im.min())\n",
    "\n",
    "def recon_to_float16(path):\n",
    "    for filename in glob.glob(path):\n",
    "        im = np.array(Image.open(filename)).astype(np.uint16)\n",
    "        #im = normalise(im)\n",
    "        im = Image.fromarray(im)\n",
    "        im.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "invalid-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/dls/science/users/lqg38422/DATA/13076/recon/*\"\n",
    "recon_to_float16(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "scientific-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13284 works - crystal is 2 loop is 1\n",
    "\n",
    "path = \"/dls/science/users/lqg38422/DATA/13284/gt/*\"\n",
    "\n",
    "vol = []\n",
    "for file in glob.glob(path):\n",
    "    im = np.array(Image.open(file))\n",
    "    vol.append(im)\n",
    "vol = np.stack(vol)\n",
    "idx_1 = vol == 1\n",
    "idx_2 = vol == 2\n",
    "vol[idx_1] = 2\n",
    "vol[idx_2] = 1\n",
    "filenames = glob.glob(path)\n",
    "for n in range(len(vol)):\n",
    "    im = vol[n].astype(np.uint8)\n",
    "    im = Image.fromarray(im)\n",
    "    im.save(filenames[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "breathing-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13076 - fix reconstruction dimensions order - convert uint8 to >u2 + correct categories\n",
    "\n",
    "def gt_to_uint8(path):\n",
    "    for filename in glob.glob(path):\n",
    "        im = np.array(Image.open(filename))\n",
    "        im = im.astype(np.uint8)\n",
    "        im = Image.fromarray(im).convert('RGB').convert('L')\n",
    "        im.save(filename)\n",
    "               \n",
    "path = \"/dls/science/users/lqg38422/DATA/13076/gt/*\"\n",
    "gt_to_uint8(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "streaming-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13270 - there's a 4 in image 606 - values are [0,2,3,4] - if != 0 -=1\n",
    "\n",
    "path = \"/dls/science/users/lqg38422/DATA/13270/gt/*\"\n",
    "\n",
    "vol = []\n",
    "for file in glob.glob(path):\n",
    "    im = np.array(Image.open(file))\n",
    "    vol.append(im)\n",
    "vol = np.stack(vol)\n",
    "np.unique(vol)\n",
    "vol[vol != 0] -= 1\n",
    "filenames = glob.glob(path)\n",
    "for n in range(len(vol)):\n",
    "    im = vol[n].astype(np.uint8)\n",
    "    im = Image.fromarray(im)\n",
    "    im.save(filenames[n])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "familiar-beach",
   "metadata": {},
   "source": [
    "# Function to turn images to turn images to uint8 (8 bits)\n",
    "def image_to_uint8(filenames, dtype=np.uint8):\n",
    "    filenames = glob.glob(filenames)\n",
    "    for f in filenames:\n",
    "        im = Image.open(f)\n",
    "        im = np.array(im).astype(dtype)\n",
    "        im = Image.fromarray(im)\n",
    "        im.save(f)\n",
    "        \n",
    "path = \"/dls/science/users/lqg38422/DATA/13076/gt/*.tif\"\n",
    "uint16_to_uint8(path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "wooden-reporter",
   "metadata": {},
   "source": [
    "# PAD FOLDER\n",
    "\n",
    "pad_folder(\"/dls/science/users/lqg38422/DATA/TRAIN/recon/*\", (900, 900))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "better-database",
   "metadata": {},
   "source": [
    "pad_folder(\"/dls/science/users/lqg38422/DATA/TRAIN/gt/*\", (900, 900))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "active-rochester",
   "metadata": {},
   "source": [
    "# 13737 change 2 - 3\n",
    "\n",
    "path = \"/dls/science/users/lqg38422/DATA/13737/gt/*\"\n",
    "\n",
    "vol = []\n",
    "for file in glob.glob(path):\n",
    "    im = np.array(Image.open(file))\n",
    "    vol.append(im)\n",
    "vol = np.stack(vol)\n",
    "idx_1 = vol == 1\n",
    "idx_2 = vol == 2\n",
    "idx_3 = vol == 3\n",
    "vol[idx_1] = 3\n",
    "vol[idx_2] = 1\n",
    "vol[idx_3] = 2\n",
    "filenames = glob.glob(path)\n",
    "for n in range(len(vol)):\n",
    "    im = vol[n].astype(np.uint8)\n",
    "    im = Image.fromarray(im)\n",
    "    im.save(filenames[n])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fifty-watershed",
   "metadata": {},
   "source": [
    "# 14253: crystal = 3, loop = 1, liquor = 2 (3=1, 1=2, 2=3)\n",
    "\n",
    "path = \"/dls/science/users/lqg38422/DATA/14253/gt/*\"\n",
    "\n",
    "vol = []\n",
    "for file in glob.glob(path):\n",
    "    im = np.array(Image.open(file))\n",
    "    vol.append(im)\n",
    "vol = np.stack(vol)\n",
    "idx_1 = vol == 1\n",
    "idx_2 = vol == 2\n",
    "idx_3 = vol == 3\n",
    "vol[idx_1] = 2\n",
    "vol[idx_2] = 3\n",
    "vol[idx_3] = 1\n",
    "filenames = glob.glob(path)\n",
    "for n in range(len(vol)):\n",
    "    im = vol[n].astype(np.uint8)\n",
    "    im = Image.fromarray(im)\n",
    "    im.save(filenames[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-prompt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
